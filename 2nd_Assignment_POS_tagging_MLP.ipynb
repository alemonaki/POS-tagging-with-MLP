{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#pip install tensorflow numpy sklearn"
   ],
   "metadata": {
    "collapsed": true,
    "id": "5MeAvTmYNZ_1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets\n",
    "!pip install conllu\n",
    "!pip install --upgrade datasets"
   ],
   "metadata": {
    "collapsed": true,
    "id": "rKJwnjW2PXrr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "61a06e32-c96f-4fab-a26d-1d65c5dac449"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#!rm -rf ~/.cache/huggingface/datasets\n",
    "#!rm -rf /root/.cache/huggingface/datasets\n",
    "#!rm -rf /content/.cache/huggingface/datasets"
   ],
   "metadata": {
    "id": "8LtYS8_UeOpi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the data"
   ],
   "metadata": {
    "id": "h7PxtDSLjug5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from datasets import load_dataset"
   ],
   "metadata": {
    "id": "hLULYKXHNlzd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"universal_dependencies\", \"en_ewt\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "dev_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382,
     "referenced_widgets": [
      "de1a8030b3c446049d125eda52639cc2",
      "83f094c1cbd0448ea257c93bd4d18b00",
      "8386e83fc49142f192dffee62261083c",
      "5253f01c5a97457daa6cb2dd61ec8f18",
      "89ef8dbff43741f1b1531f5cef25e773",
      "6f4010e0239941a29bed0e8c146d9046",
      "bfc208e7ba714b6b8c27c7acad95a8e1",
      "402910c9ce974bf1bdfb6354c3f33483",
      "4e91fda77fdf461983d8bbe55aa4e2cc",
      "070042f5cb4e4ef296e651ef9cd2753b",
      "779010886eda403b9092cb38dd9636f4",
      "b39be7b8ecbd4ee4a78e562b25d34ff6",
      "53574e133b124e5fa6ec6a108de87805",
      "b754a6c1c948472d8701ce6ffab666ea",
      "57d3f74335574ba28041df035b72445c",
      "27061949c6804f81aa17e00f1329d913",
      "2c014d5065f2416a8e7382598f2a02f3",
      "32b7fb17002944608353dc31764bccac",
      "e9a4ff98a5044023b01635ead72507b1",
      "18ca29aea9bd422b83b3a52edb99c385",
      "5ea0571a6adf487aaffdb2a180a15abc",
      "3bce2465ff93459e83ad5e165ab4f283",
      "688d2744204948328eeaa9d2af99afeb",
      "9a530b3754934a99b79e0ac940224fff",
      "2a014716e1fe4bc1a2fb597377c17549",
      "574a66763f2640e3acdbeecaa37a5ea9",
      "c66de1686802444fb7da4719b42f305e",
      "8a77a883f788495289257c947cafc2e9",
      "9f6e6f3acf794d8a91aa26f80d2891de",
      "31095cd4c34944079b741f7dadde9d3e",
      "16052b2d1b64448b9d03ac4cbbf5936a",
      "43f6166547d44057aad03f523b661e04",
      "a496e66a6c8644469671f46bd335914d",
      "24452c21daea4669b867e197abd6d929",
      "c36c78b2da454e88a870c925f7748eb4",
      "b609bced56ab471787fcd1c03c07947f",
      "6f27784497484fe790d989f4d706774b",
      "d096ba6e6f504e8c80e6f005eb606083",
      "63165f24e255410dad9b418aa9652d57",
      "1b7dc0a4df7c4ba198bb1648e10356b6",
      "329064cb2a3d4449b829b30a09539685",
      "2fff61f9bd544c1590edc631ec6c537c",
      "dbb642d167f8403d9a18d0906dfc5070",
      "6796513b303f4f36ba544a979327433f",
      "04d75e49f2b24a3485cde49134b1ecf8",
      "3c9605288c3745ea8a59b671847f3dfd",
      "0700e8e1da5246809be84df4e31011f3",
      "0d64f009601e4faca84bc2c911ea3405",
      "754931c566954fe9a3891382883f2f8a",
      "a9b3f017baf241afa39fdaadba40a491",
      "68f0dea1d46c42b09852651406d0e4a2",
      "670651fc2be04ff69aa27cb25b298f59",
      "37edb51a57ff46ccab8f1020049c5d98",
      "44994417e09c4999a5a5109820608d5c",
      "c4a83a593a2a43bfaffbcc6ae84e4cdf",
      "6d27b0d642b24bb1bb62fb8ead5f814f",
      "67cf534cb2ca443f84ef82d299394aba",
      "759cf3e7d9104dc88168cdb9f4c8eca3",
      "39f15f1f8b9b4749810d9f57653a3e81",
      "5db4ef65063040dc8c237fd788627c03",
      "169cf34ce8b84a27b4c2abb2e9f5c235",
      "fc68330dc13e4867b38fbf4e0bbb9aaf",
      "a4f9e8ee6f664bc5ae686f859accfb4a",
      "49bc8d6968cd406982c6c7c0eec33db3",
      "4181ffd7103c433e980162634fef38e4",
      "dae3d9c31440426abdbbacf56fac4e78",
      "b2a7ca6ad1664d6e9747de78bef7f5c5",
      "a4aedf76bd7446f9b6d779de4d5e8426",
      "e1731ff241e74a2cb1df31a352ce37e6",
      "2d6a9f53bc6b4e55b381beb9e84c4de6",
      "9cb43ce1f0d14e54bc06ebfa58423695",
      "45e0f7bd751a42718fc4dbcda27ace22",
      "d4c4313767924ceca6dae4503327476e",
      "52fac2bdcfbf4180be9c1745a767f148",
      "fc127873463e4db3b3780082ddb130ef",
      "837634e0967a4e92914e0c139f05d776",
      "3f7c998e18fe499fa3ab9c78b20e6935",
      "0cb18082d7684a26960c959e2694b3aa",
      "9c3145ee4771402c8aeb1156072ab385",
      "f75c09b32b164b4087e41838de8dd61f",
      "b4dedd16cabf4f31b25f8fff8cae654d",
      "aeacd6f283404478a2c0fc8b8ff382df",
      "c6ed04449a9c478bab1e472863d37884",
      "e37e41b19711421db7d6cbe4c308abc3",
      "71c65813b8dc443b86d5d9934e303bdf",
      "1bf3061657574a6faedc43446d61ddb9",
      "94cf191b6d2c430ba9376039f4c6db9a",
      "161c70439b2641e09fa7195f965a73cc"
     ]
    },
    "collapsed": true,
    "id": "K5mlZ1mrPlpb",
    "outputId": "1c81614c-8b69-4d0b-8a0b-9698e1fd834f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data"
   ],
   "metadata": {
    "id": "dGoDWPgkR1Wf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8633bde1-b44f-41d5-e203-fec427c4a985"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess data for MLP Input"
   ],
   "metadata": {
    "id": "LvJYBPihj2Ra"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "window_size = 5\n",
    "pad_size = window_size // 2"
   ],
   "metadata": {
    "id": "0VqZ72ADSdE-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word2idx = defaultdict(lambda: len(word2idx))\n",
    "tag2idx = defaultdict(lambda: len(tag2idx))\n",
    "\n",
    "word2idx[\"<PAD>\"]\n",
    "word2idx[\"<UNK>\"]\n",
    "\n",
    "def extract_sequences(dataset):\n",
    "    sequences = []\n",
    "    for item in dataset:\n",
    "        tokens = item['tokens']\n",
    "        tags = item['upos']\n",
    "        sequences.append((tokens, tags))\n",
    "    return sequences"
   ],
   "metadata": {
    "id": "KgO7wQlNY1z_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_seqs = extract_sequences(train_data)\n",
    "dev_seqs = extract_sequences(dev_data)\n",
    "test_seqs = extract_sequences(test_data)"
   ],
   "metadata": {
    "id": "Bb-lJ43lZ8GL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_seqs[1]"
   ],
   "metadata": {
    "id": "c_V6dnVpbbzT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5843caa4-cf4b-4037-883a-5d375bca3ff6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Indexing words from training set\n",
    "for tokens, tags in train_seqs:\n",
    "    for token in tokens:\n",
    "        word2idx[token.lower()]"
   ],
   "metadata": {
    "id": "a5eZ4zffcdXO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Statistics"
   ],
   "metadata": {
    "id": "u1EwwIwceh8Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Vocabulary size: {len(word2idx)}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rItxkXeVgcpn",
    "outputId": "c77d0274-33ba-45ef-f0b7-c8f8ad60d828"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_train_sent = len(train_seqs)\n",
    "num_val_sent = len(dev_seqs)\n",
    "num_test_sent = len(test_seqs)\n",
    "print(f'training sequences length: {num_train_sent}')\n",
    "print(f'development sequences length: {num_val_sent}')\n",
    "print(f'test sequences length: {num_test_sent}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrKEJK6befhs",
    "outputId": "f2663253-cc64-4c9a-bdb2-9edc35336da5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def total_token_count(sequences):\n",
    "    return sum(len(tokens) for tokens, _ in sequences)\n",
    "\n",
    "train_token_count = total_token_count(train_seqs)\n",
    "val_token_count = total_token_count(dev_seqs)\n",
    "test_token_count = total_token_count(test_seqs)\n",
    "\n",
    "print(f'training tokens count: {train_token_count}')\n",
    "print(f'development tokens count: {val_token_count}')\n",
    "print(f'test tokens count: {test_token_count}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aywGyMoKewS7",
    "outputId": "11bf9cb5-daf0-4c47-bbe4-9b913ff36da1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def average_sentence_length(sequences):\n",
    "    return sum(len(tokens) for tokens, _ in sequences) / len(sequences)\n",
    "\n",
    "avg_train_length = average_sentence_length(train_seqs)\n",
    "avg_val_length = average_sentence_length(dev_seqs)\n",
    "avg_test_length = average_sentence_length(test_seqs)\n",
    "\n",
    "print(f'average training sentence length: {avg_train_length:.2f}')\n",
    "print(f'average development sentence length: {avg_val_length:.2f}')\n",
    "print(f'average test sentence length: {avg_test_length:.2f}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQ9mAKlCfmQJ",
    "outputId": "fd150b58-8809-446d-8c0a-fb62d724d8bb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_unique_tags(sequences):\n",
    "    tag_set = set()\n",
    "    for _, tags in sequences:\n",
    "        tag_set.update(tags)\n",
    "    return tag_set\n",
    "\n",
    "pos_tags = get_unique_tags(train_seqs)\n",
    "num_tags = len(pos_tags)\n",
    "int2tag = train_data.features[\"upos\"].feature.int2str\n",
    "\n",
    "print(f'unique POS tags: {int2tag(pos_tags)}')\n",
    "print(f'number of tags: {num_tags}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vuR2pEJEfwgX",
    "outputId": "a7ffb622-61a7-4bb8-de76-732a0f6fc75e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Top 5 most frequent tags"
   ],
   "metadata": {
    "id": "fiJ9U9JUKdou"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_tag_freqs(sequences):\n",
    "    counter = Counter()\n",
    "    for _, tag_ids in sequences:\n",
    "        counter.update(tag_ids)\n",
    "    return counter\n",
    "\n",
    "tag_freqs = get_tag_freqs(train_seqs)\n",
    "for tag_id, count in tag_freqs.most_common(5):\n",
    "    print(f\"{int2tag(tag_id)}: {count}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qcEfRE5xFBh",
    "outputId": "216adf51-8e90-4926-8acc-b593aee210bd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Windowed Input Features"
   ],
   "metadata": {
    "id": "1aOWnsqKkIW0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def create_windows(sequences, word2idx, windowSize):\n",
    "    pad = ['<PAD>'] * (window_size // 2)\n",
    "    X, y = [], []\n",
    "    for tokens, tags in sequences:\n",
    "        tokens = pad + [t.lower() for t in tokens] + pad\n",
    "        for i in range(len(tags)):\n",
    "            window = tokens[i:i + window_size]\n",
    "            X.append([word2idx.get(w, word2idx[\"<UNK>\"]) for w in window])\n",
    "            y.append(tags[i])\n",
    "    return np.array(X), np.array(y)"
   ],
   "metadata": {
    "id": "ek_SUgyBjD-7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, y_train = create_windows(train_seqs, word2idx, window_size)\n",
    "X_dev, y_dev = create_windows(dev_seqs, word2idx, window_size)\n",
    "X_test, y_test = create_windows(test_seqs, word2idx, window_size)"
   ],
   "metadata": {
    "id": "axezzGhat6bS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download GloVe (pre-trained embeddings)"
   ],
   "metadata": {
    "id": "4XK0z0hvxdaR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests, zipfile, io\n",
    "\n",
    "url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "    zip_ref.extract(\"glove.6B.100d.txt\", path=\".\")"
   ],
   "metadata": {
    "id": "DHvSvf02wEzi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_glove_embeddings(glove_path, word2idx, embedding_dim=100):\n",
    "    # Initialize random embeddings\n",
    "    embeddings = np.random.uniform(-0.05, 0.05, (len(word2idx), embedding_dim)).astype(np.float32)\n",
    "    embeddings[word2idx[\"<PAD>\"]] = np.zeros(embedding_dim)\n",
    "    embeddings[word2idx[\"<UNK>\"]] = np.random.uniform(-0.05, 0.05, embedding_dim).astype(np.float32) # Initialize <UNK> randomly\n",
    "\n",
    "\n",
    "    # Load GloVe into a dict\n",
    "    glove_dict = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype=np.float32)\n",
    "            glove_dict[word] = vector\n",
    "\n",
    "    # Fill in known words\n",
    "    found = 0\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in glove_dict:\n",
    "            embeddings[idx] = glove_dict[word]\n",
    "            found += 1\n",
    "\n",
    "    print(f\"Matched {found} / {len(word2idx)} words from your vocab ({found / len(word2idx):.2%})\")\n",
    "    return embeddings\n"
   ],
   "metadata": {
    "id": "dYOvBkMixjMS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "glove_path = \"glove.6B.100d.txt\"  # Download from https://nlp.stanford.edu/projects/glove/\n",
    "embedding_matrix = load_glove_embeddings(glove_path, word2idx, embedding_dim=100)"
   ],
   "metadata": {
    "id": "jgVcnsf6yjoN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9a0266d2-0681-4cc4-9dcb-d5e2bb8aa1b9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_matrix.shape"
   ],
   "metadata": {
    "id": "P93LBjb3ywsa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1ec8f694-8678-4cd0-9eff-d1120d1dafa3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word2idx[1]"
   ],
   "metadata": {
    "id": "S4WLiaI6y0No",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b7b17ff3-4fdb-45ae-96ae-d63ef963e45f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if embedding_matrix.shape[0] != len(word2idx):\n",
    "    diff = len(word2idx) - embedding_matrix.shape[0]\n",
    "    # If word2idx has more entries, extend embedding matrix with random vectors\n",
    "    if diff > 0:\n",
    "        padding = np.random.uniform(-0.05, 0.05, (diff, embedding_matrix.shape[1])).astype(np.float32)\n",
    "        embedding_matrix = np.concatenate([embedding_matrix, padding], axis=0)\n",
    "    # If embedding_matrix has more entries, trim it to match word2idx (less likely)\n",
    "    elif diff < 0:\n",
    "        embedding_matrix = embedding_matrix[:len(word2idx)]"
   ],
   "metadata": {
    "id": "0ilq9uPXWpDq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP"
   ],
   "metadata": {
    "id": "kzbUI92n55eE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report,precision_recall_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "BLD8Fngl59R3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class PoSMLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, windowSize,\n",
    "                 hidden_layers=None, dropout=0.0, batch_norm=False,\n",
    "                 layer_norm=False, num_classes=20, embedding_weights=None,\n",
    "                 freeze_embeddings=True):\n",
    "        super(PoSMLP, self).__init__()\n",
    "\n",
    "        # 1. Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embedding_weights is not None:\n",
    "            self.embedding.weight.data.copy_(torch.tensor(embedding_weights))\n",
    "            self.embedding.weight.requires_grad = not freeze_embeddings\n",
    "\n",
    "        input_dim = embedding_dim * window_size  # e.g. 100 x 5 = 500\n",
    "\n",
    "        # 2. Feedforward layers\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        if hidden_layers:\n",
    "            for hidden_dim in hidden_layers:\n",
    "                layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                if batch_norm:\n",
    "                    layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "                if layer_norm:\n",
    "                    layers.append(nn.LayerNorm(hidden_dim))\n",
    "                if dropout > 0:\n",
    "                    layers.append(nn.Dropout(dropout))\n",
    "                prev_dim = hidden_dim\n",
    "\n",
    "        # 3. Output layer\n",
    "        layers.append(nn.Linear(prev_dim, num_classes))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, window_size)\n",
    "        emb = self.embedding(x)                    # (batch_size, window_size, embedding_dim)\n",
    "        flat = emb.view(emb.size(0), -1)           # (batch_size, window_size * embedding_dim)\n",
    "        return self.net(flat)                      # logits over POS classes\n"
   ],
   "metadata": {
    "id": "rUmoLSR12BVo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = PoSMLP(\n",
    "    vocab_size=len(word2idx),\n",
    "    embedding_dim=100,\n",
    "    windowSize=window_size,\n",
    "    hidden_layers=[128, 64],\n",
    "    dropout=0.5,\n",
    "    batch_norm=False,\n",
    "    layer_norm=False,\n",
    "    num_classes=len(train_data.features[\"upos\"].feature.names),\n",
    "    embedding_weights=embedding_matrix,\n",
    "    freeze_embeddings=True )"
   ],
   "metadata": {
    "id": "vP1tcrsg6AgS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20, model_name=\"\"):\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = None\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state_dict = model.state_dict()\n",
    "\n",
    "    # Save the best model ONCE after training\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    save_path = \"/content/drive/MyDrive/best_mlp_model.pth\"\n",
    "    torch.save(best_state_dict, save_path)\n",
    "    print(f\"\\nâœ… Best model saved ONCE to: {save_path}\")\n",
    "\n",
    "\n",
    "    print(f\"\\nBest model saved as: {best_model_path}\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "    plt.plot(val_losses, label=\"Validation Loss\", marker='s')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training & Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, val_losses\n"
   ],
   "metadata": {
    "id": "HJQu3gWI6egk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            y_true.extend(y_batch.cpu().tolist())\n",
    "            y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"\\nEvaluation:\\nAccuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    return accuracy, precision, recall, f1\n"
   ],
   "metadata": {
    "id": "P7Y3HV2R6gET"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hyperparams_grid = [\n",
    "    {\"hidden_layers\": [128], \"dropout\": 0.3},\n",
    "    {\"hidden_layers\": [128, 64], \"dropout\": 0.3},\n",
    "    {\"hidden_layers\": [256], \"dropout\": 0.5},\n",
    "    {\"hidden_layers\": [256, 128, 64], \"dropout\": 0.4},\n",
    "    {\"hidden_layers\": [128, 64], \"batch_norm\": True, \"dropout\": 0.3},\n",
    "    {\"hidden_layers\": [128, 64], \"layer_norm\": True, \"dropout\": 0.3}\n",
    "]\n"
   ],
   "metadata": {
    "id": "0Jx2ScWuCKWW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tune_and_compare_models(hyperparams_grid, word2idx, embedding_matrix, train_loader, val_loader, tag_count):\n",
    "    best_f1 = 0.0\n",
    "    best_config = None\n",
    "    best_model_state = None\n",
    "    results = []\n",
    "\n",
    "    for i, params in enumerate(hyperparams_grid):\n",
    "        print(f\"\\n=== Trying Model {i+1}: {params} ===\")\n",
    "\n",
    "        model = PoSMLP(\n",
    "            vocab_size=len(word2idx),\n",
    "            embedding_dim=100,\n",
    "            windowSize=5,\n",
    "            hidden_layers=params[\"hidden_layers\"],\n",
    "            dropout=params[\"dropout\"],\n",
    "            batch_norm=params.get(\"batch_norm\", False),\n",
    "            layer_norm=params.get(\"layer_norm\", False),\n",
    "            num_classes=tag_count,\n",
    "            embedding_weights=embedding_matrix,\n",
    "            freeze_embeddings=True\n",
    "        )\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20, model_name=f\"model_{i+1}\")\n",
    "\n",
    "        acc, prec, rec, f1 = evaluate_model(model, val_loader)\n",
    "\n",
    "        results.append({\n",
    "            \"config\": params,\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1\": f1\n",
    "        })\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_config = params\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    print(\"\\n=== Tuning Complete ===\")\n",
    "    print(f\"Best Config: {best_config} with F1 = {best_f1:.4f}\")\n",
    "    return best_config, best_model_state, results\n"
   ],
   "metadata": {
    "id": "NYOI0O2KDPN7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_dataloader(X, y, batch_size=64, shuffle=False):\n",
    "    tensor_X = torch.tensor(X, dtype=torch.long)\n",
    "    tensor_y = torch.tensor(y, dtype=torch.long)\n",
    "    dataset = TensorDataset(tensor_X, tensor_y)\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ],
   "metadata": {
    "id": "u2Ths0kmFsna"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = create_dataloader(X_train, y_train, batch_size=128, shuffle=True)\n",
    "dev_loader = create_dataloader(X_dev, y_dev, batch_size=128, shuffle=False)\n",
    "test_loader = create_dataloader(X_test, y_test, batch_size=128, shuffle=False)"
   ],
   "metadata": {
    "id": "XNVYqcYGc9s9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tag_count = len(train_data.features[\"upos\"].feature.names)\n",
    "\n",
    "best_config, best_model_state, all_results = tune_and_compare_models(\n",
    "    hyperparams_grid, word2idx, embedding_matrix,\n",
    "    train_loader, dev_loader, tag_count )"
   ],
   "metadata": {
    "id": "ubbMj5SXEo3Y",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "8ae472a7-dc8e-4ca4-ab5f-74d7f07e535f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# load best model weights\n",
    "best_model = PoSMLP(\n",
    "    vocab_size=len(word2idx),\n",
    "    embedding_dim=100,\n",
    "    windowSize=5,\n",
    "    hidden_layers=best_config[\"hidden_layers\"],\n",
    "    dropout=best_config[\"dropout\"],\n",
    "    batch_norm=best_config.get(\"batch_norm\", False),\n",
    "    layer_norm=best_config.get(\"layer_norm\", False),\n",
    "    num_classes=len(train_data.features[\"upos\"].feature.names),\n",
    "    embedding_weights=embedding_matrix,\n",
    "    freeze_embeddings=True)\n",
    "\n",
    "best_model.load_state_dict(best_model_state)"
   ],
   "metadata": {
    "id": "4Wz5AjhgdarQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7abe905e-1cc4-46e8-897d-bfc8f3b03bdd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for evaluation metrics\n",
    "def evaluate_model_with_auc(model, data_loader, idx2tag):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            y_true.extend(y_batch.cpu().tolist())\n",
    "            y_pred.extend(preds.cpu().tolist())\n",
    "            y_probs.extend(probs.cpu().tolist())\n",
    "\n",
    "    # Basic scores\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(\"\\nðŸ“Š Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[idx2tag[i] for i in range(len(idx2tag))]))\n",
    "\n",
    "    # AUC\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(len(idx2tag))))\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    pr_auc = {}\n",
    "    auc_sum = 0\n",
    "    valid_classes = 0\n",
    "\n",
    "    for i, class_name in enumerate(idx2tag):\n",
    "      if np.sum(y_true_bin[:, i]) == 0:\n",
    "            continue  # skip classes not in y_true\n",
    "      precision_vals, recall_vals, _ = precision_recall_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "      score = auc(recall_vals, precision_vals)\n",
    "      pr_auc[class_name] = score\n",
    "      auc_sum += score\n",
    "      valid_classes += 1\n",
    "\n",
    "    macro_auc = auc_sum / valid_classes if valid_classes > 0 else 0\n",
    "    print(\"\\nðŸ“ˆ Precision-Recall AUC per tag:\")\n",
    "    for tag, score in pr_auc.items():\n",
    "        print(f\"{tag:>6}: {score:.4f}\")\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Macro-averaged PR AUC: {macro_auc:.4f}\")\n"
   ],
   "metadata": {
    "id": "WeGrAV8ur4Nn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Train Set ---\")\n",
    "evaluate_model_with_auc(best_model, train_loader, train_data.features[\"upos\"].feature.names)\n",
    "\n",
    "print(\"\\n--- Dev Set ---\")\n",
    "evaluate_model_with_auc(best_model, dev_loader, train_data.features[\"upos\"].feature.names)\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "evaluate_model_with_auc(best_model, test_loader, train_data.features[\"upos\"].feature.names)\n"
   ],
   "metadata": {
    "id": "5shBpg71sQcg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5e803d1b-34c8-45cf-86cb-185277bd783b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline"
   ],
   "metadata": {
    "id": "3OEIfD2V_Z0D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# word_to_tag_counter: {\"cat\": {\"NOUN\": 12, \"VERB\": 1}, ...}\n",
    "# most_frequent_tag: the most common POS tag overall\n",
    "def build_baseline_dict_numeric(sequences):\n",
    "    word_tag_counts = defaultdict(Counter)\n",
    "    tag_counts = Counter()\n",
    "\n",
    "    for tokens, tag_ids in sequences:\n",
    "        for word, tag in zip(tokens, tag_ids):\n",
    "            word_tag_counts[word.lower()][tag] += 1\n",
    "            tag_counts[tag] += 1\n",
    "\n",
    "    most_frequent_tag = tag_counts.most_common(1)[0][0]\n",
    "    word_to_best_tag = {word: tag_counter.most_common(1)[0][0] for word, tag_counter in word_tag_counts.items()}\n",
    "    return word_to_best_tag, most_frequent_tag\n"
   ],
   "metadata": {
    "id": "PzhxQfVA78-E"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_baseline_numeric(sequences, word_to_best_tag, most_frequent_tag):\n",
    "    y_true, y_pred = [], []\n",
    "    for tokens, tag_ids in sequences:\n",
    "        for word, true_tag in zip(tokens, tag_ids):\n",
    "            predicted_tag = word_to_best_tag.get(word.lower(), most_frequent_tag)\n",
    "            y_true.append(true_tag)\n",
    "            y_pred.append(predicted_tag)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(\"\\nðŸ”¹ Baseline Evaluation:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    return accuracy, precision, recall, f1\n"
   ],
   "metadata": {
    "id": "CspIq_u9w-w-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Baseline\n",
    "word_to_best_tag, most_frequent_tag = build_baseline_dict_numeric(train_seqs)\n",
    "\n",
    "dev = evaluate_baseline_numeric(dev_seqs, word_to_best_tag, most_frequent_tag)\n",
    "test = evaluate_baseline_numeric(test_seqs, word_to_best_tag, most_frequent_tag)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J49JZgoFxg2G",
    "outputId": "82a39661-7910-4421-8774-91c4f19b987e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most frequent tag for unknown words"
   ],
   "metadata": {
    "id": "BOppA4Yz_x7S"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "int2tag = train_data.features[\"upos\"].feature.int2str"
   ],
   "metadata": {
    "id": "7Ha5k8WZchuJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Most frequent tag overall (ID):\", most_frequent_tag)\n",
    "print(\"Most frequent tag overall (label):\", int2tag(most_frequent_tag))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwl3XNoYzQbJ",
    "outputId": "381980db-bc67-4990-c00b-c4b2faa64484"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word = \"is\"\n",
    "tag_id = word_to_best_tag.get(word.lower(), most_frequent_tag)\n",
    "print(f'Most frequent tag for \"{word}\": {int2tag(tag_id)}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YP02nfxdKB4q",
    "outputId": "9aa8cbd8-add7-4470-966a-281b0cad64b7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word = \":\"\n",
    "tag_id = word_to_best_tag.get(word.lower(), most_frequent_tag)\n",
    "print(f'Most frequent tag for \"{word}\": {int2tag(tag_id)}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MJHAfc5cqgg",
    "outputId": "41bef1b2-487b-434c-afdf-9db8358b9624"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"flerb\" in word2idx)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtcwTZA2dd15",
    "outputId": "c431755d-0598-41ff-d0c6-d521974d62b5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word = \"flerb\"\n",
    "tag_id = word_to_best_tag.get(word.lower(), most_frequent_tag)\n",
    "print(f'Most frequent tag for \"{word}\": {int2tag(tag_id)}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NF7Vlofdde_O",
    "outputId": "623f3d8c-eb22-4b6e-882c-a31edf78d20d"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}